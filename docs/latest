<!DOCTYPE html>
<html lang="en"><head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>notech.ie</title>
<style>
body {
  margin-top: 0;
  margin-bottom: 0;
}
#hcontent {
  height: 100vh;
  padding-right: 1vw;
  width: 50em;
  max-width: 98vw;
  overflow: auto;
  resize: horizontal;
}
</style>
</head><body>
<div id=hcontent>
<h1>notech.ie</h1>
<ul>
<li><a href=#briefquiz>briefquiz</a> for kids could be a fun game.</li>
<li><a href=#goldentesting>goldentesting</a> is an alternative to a unittesting.</li>
<li><a href=#postmore>postmore</a> to keep emails shorter.</li>
<li><a href=#slowpals>slowpals</a> is about a penpals site idea.</li>
</ul>

<h2 id="briefquiz">briefquiz</h2>
<p>
in /challenge i mentioned an idea of a challenge event i could run.
but lately i was thinking a bit about it.
perhaps that idea is a bit too impersonal, too steep as a starting point.
i remembered how i all started developing my interest in computers
at about an age of 10.
there was actually a &quot;competition&quot; aimed at my level.
you could sign up for it
and then they would send you some questions via snail mail.
then you would anwser them and send the answers back via snail mail.
i started participating in this.
but when i was starting, i didn&apos;t really know the answers.
so one of the infotech teachers in the school started helping me.
we worked through the problems together.
</p>

<p>
two things happened here:
first, the letter format was a very good,
soft introduction to the world of computing.
second, i basically got a mentor out of this.
i spent a lot of time at that teacher.
i ran to him even between classes so that he explain some questions to me.
i&apos;m not sure why he invested so much time in me
(i took away his breaks after all),
but i&apos;m glad he did, since it helped me significantly.
</p>

<p>
so based on these observations and my previous ideas,
i think i&apos;d want to make a challenge site that consists of two parts.
there&apos;s a &quot;qualification&quot; phase that is done purely through email,
and there&apos;s a &quot;challenge&quot; phase
where the participants demonstrate their skills in person
a bit similarly to what i described in /challenge.
</p>

<p>
i think the qualification phase is important
to light the fire in the kids&apos; hearts.
i imagine it as follows:
a kid (or even adults if they wish) would sign up for my site.
then i&apos;d send the kid some easy questions.
e.g.:
</p>

<ul><li>
  what was the first computer?
</li><li>
  what are the computers good at doing?
</li><li>
  how do you look up information when you don&apos;t know something?
</li><li>
  how would you determine how many characters a piece of text has?
</li><li>
  you have a file with 1000 numbers.
  how would you create another file that has the each of those numbers doubled?
</li>
</ul>

<p>
then on later rounds the questions would become harder:
</p>

<ul><li>
  what is a programming language?
</li><li>
  what is a shell (e.g. bash)?
</li><li>
  what is a shell script?
</li><li>
  what is linux?
</li><li>
  where is javascript used?
</li><li>
  what is compilation?
</li><li>
  how would you compile and run some c code?
</li><li>
  write a hello world c program!
</li>
</ul>

<p>
and stuff like that.
about 2-4 questions per round.
i&apos;d expect that the kids send the answer back in an email.
and i&apos;d limit the answer to 300 characters,
they would need to fit their answers into that limit.
</p>

<p>
the kids can use any help they need, i wouldn&apos;t really care.
and then i would answer each email individually.
depending on the letter i might even get a bit philosophical:
for example if for that information lookup question i get a googling answer,
i might respond that using teachers and mentors is also a good source,
and for some type of questions and problems, it&apos;s the only source.
if they didn&apos;t answer the questions correctly,
i might ask them why did that happen,
otherwise i&apos;d just send them the next set of questions.
</p>

<p>
if they persist through the qualification rounds (about 4-5 rounds)
i&apos;d introduce them to the &quot;challenges&quot; where you have actual coding tasks.
i&apos;d create 90 static &quot;challenges&quot;.
90 because i want to refer to the challenges as a number starting from 10.
keep in mind that these would be relatively easy challenges,
wouldn&apos;t go deep into the algorithms.
the idea is to keep them relatively easily achievable,
so that the kids can get a sense of achievement,
that would lead them to start studying these things deeper,
and maybe go on to the more mature national contests
to further hone their skills.
and the challenges have to remain relatively easy,
so that their cs teacher can easily work with the kids.
</p>

<p>
i&apos;d make about 10 shell scripting tasks,
about 40 c tasks, and about 40 javascript tasks.
i think i can cover most important things with that.
the c and javascript challenges would be very similar
so basically i would be asking them to implement the same thing
in two entirely different languages.
the challenges themselves would be public,
anybody can read and prepare for them on their own.
think of relatively easy tasks,
like guess what number i&apos;m thinking or
draw a large ascii art christmas tree.
</p>

<p>
however the act of solving these tasks wouldn&apos;t be conducted online.
we&apos;d probably go to a computer lab after school together,
and i&apos;d expect that the kid demonstrates writing the solution without any help.
i wouldn&apos;t allow any references.
they shall memorize the syntax and the function parameters.
on the other hand they can try any time and retry any number of times.
so there&apos;s no pressure.
and to save time, they can do any number of challenges per session.
even one challenge per session is fine.
the challenges are intended to be easy enough
that one can solve multiple ones in a short amount of time,
depending on their experience.
if they manage to solve the problem without help,
i&apos;ll consider their challenge complete.
they can now either try another one,
or go home to prepare for the next one.
</p>

<p>
i&apos;ll keep their solution for myself,
and after the session i&apos;d send them a review of their solution
or suggest improvements.
and if somebody manages to get through all the 90 challenges,
i&apos;ll add them to a &quot;hall of fame&quot; somewhere on the internet
or maybe even to a physical poster somewhere (e.g. on a school wall).
</p>

<p>
i also figured out how could i start the whole process:
when my kid becomes school age,
i&apos;m pretty sure there will be parent-teacher meetings.
i could ask the teachers on such occassions
if they were willing to advertise my challenges to the older kids.
starting with a single school is fine,
and from that on, i&apos;m hoping to rely on a word of mouth.
if that doesn&apos;t work out then i need to improve my product until it does.
i wouldn&apos;t want more few kids signing up for this though.
more than a dozen would be too much.
if i get more, i&apos;d just increase the difficulty of the qualification questions
to cull the less motivated ones.
</p>

<p>
or maybe rather than using emails,
i should stick to letters via snail mail
to cull out the less motivated ones (the ones lazy to go to the post office).
physical letter exchange might actually give it some extra excitement,
and it also allows me respond relatively slowly,
so that i can keep the pace of the whole thing is relatively slow.
this also requires some token amount of money to participate,
so i would be somewhat protected from spam
or from a suddenly very high subscription rate.
</p>

<p>
and i could run this here in switzerland even if i don&apos;t speak german well.
i can just keep everything in english
and let the kids deal with the english rather than me with the german.
at least they would have some extra motivation to learn english.
although i&apos;d probably accept german answers too but i wouldn&apos;t document this.
</p>

<p>
and i would only accept people from my local city.
i don&apos;t really want to deal with people that i can&apos;t meet personally.
i just want to give some interactive game for the local community.
</p>

<p>
more specifically i just want to give opportunity to kids
similar to what i received as a kid and more.
i very much wanted to get my schoolmates into coding too,
but nobody was that much interested.
even if i managed to get some people into this,
the competitions were way too fierce for them to keep along for long.
my hope with such a forgiving place would be to keep them interested.
the only way to lose is to give up
rather than being plain unlucky or not smart enough.
the kids can even prepare each other for my exams.
</p>

<p>
i know that there are nice online communities like khan academy.
but i can compare my experience with online and offline competitions:
offline competitions, one where i actually am next to the others
were usually a more exhilarating experience.
a person giving you some recognition in front of others feels more exciting
than watching a robot telling you that you did good
while you sit alone in a dark room, isolated from the world.
i just want to try giving such an experience for the next generation.
i think this idea could totally give that with a really little effort.
but it still requires effort from my part, so we&apos;ll see if i ever start this.
</p>

<h2 id="goldentesting">goldentesting</h2>
<p>
ugh, i really hate unittests.
they might look nice for some trivial cases
but for modules requiring more complicated setups and dependencies
they just feel like boring busywork.
and every time i want to make a change,
i&apos;m now required to maintain the unittests too.
sure, they catch an error sometimes,
but more often i&apos;m making an intentional change,
and now i have to implement that change at multiple places.
i often dread making changes
because i don&apos;t want to deal with the weird unittests some projects have.
</p>

<p>
but here&apos;s the good news:
i firmly believe all this unittesting madness will go away
when people learn that there is a much better alternative: goldentesting.
i think that&apos;s the most common term for this.
but i heard the terms of output testing or gold master testing too.
the primary reason it&apos;s not super common yet is
that there&apos;s no good generic tooling for it.
but i&apos;m pretty sure tools will slowly get there.
though it&apos;s used in some niche areas for a very long time already.
</p>

<p>
the unittest idea is this: you write code and litter it with assertions.
the goldentest idea is this: you write code and emit text to stdout.
during code review you just need to review the diffs,
you don&apos;t need to maintain the assertions manually.
</p>

<p>
suppose you write some c++ class like this:
</p>

<pre>
  class mystring { ... };
</pre>

<p>
unittests could look like this (oversimplified):
</p>

<pre>
  int main() {
    mystring s(&quot;helló&quot;);
    assert(s.length() == 6);
    assert(s.size() == 6);
    return 0;
  }
</pre>

<p>
goldentests would look like this (oversimplified):
</p>

<pre>
  int main() {
    mystring s(&quot;helló&quot;);
    printf(&quot;%s length %d\n&quot;, s.c_str(), (int)s.length());
    printf(&quot;%s size %d\n&quot;, s.c_str(), (int)s.size());
    return 0;
  }
</pre>

<p>
running this code would then output this:
</p>

<pre>
  helló length 6
  helló size 6
</pre>

<p>
you might be inclined to commit this output next to the code,
but that&apos;s a bit spammy.
however this is where better tooling could come handy:
that tool could run the test binary at both old and new versions,
and then just present you the diff
that you and the reviewer must explicitly acknowledge before merging.
</p>

<p>
for example let&apos;s assume that some user comes along
and wants that the length() function should be unicode aware.
if you simply make the change in your code
then both unit and goldentests will fail.
the unittest will fail with an assertion
that you then have to manually fix.
the goldentest will present you this diff:
</p>

<pre>
  -helló length 6
  +helló length 5
   helló size 6
</pre>

<p>
all you and the reviewer needs to do here is to acknowledge the diff.
the commit itself doesn&apos;t need to be littered with the test changes.
after the merge, you don&apos;t need to worry about this diff anymore.
</p>

<p>
you don&apos;t even need to hardcode that &quot;helló&quot; string.
it can come from from the stdin.
then you can easily create multiple testcases
simply by running this test binary on multiple inputs.
</p>

<p>
what is the function of the tests even?
i believe there are two main functions:
increase our confidence that the code is correct,
and to catch inadvertent regressions.
i claim that goldentests can do both with greater ease.
</p>

<p>
how do you get confident that your code is correct in general?
you usually write some code and then check that it is doing the expected things.
with goldentests you pretty much stop here and commit.
with unittests you go one step further:
you add assertions for those expectations.
basically you are setting up a trap for future maintainers
to painstakingly maintain your assertions.
in the goldentests those assertions are still there
but rather in an implicit manner so it still achieves the same goals.
</p>

<p>
and they are just as effective catching regressions as the unittests.
you just need the right tooling
to enforce the same standards for goldentests as for the unittests.
</p>

<p>
goldentests scale much better for larger codebases.
suppose you are maintaining some logging library.
and now you suddenly want to change its output format.
more likely than not, in the unittest world there are assertions
that are asserting your very specific line format for some reason.
if you want to change the format,
then you have to create a massive change that changes all such tests too.
with goldentests this will just create a massive diff.
however chances are that the diff will be very redundant
and with some additional tooling (again, more tooling)
you would be able to canonicalize all the diffs
and you would end up with a small diff that you can easily inspect
and determine that your change doesn&apos;t change the logic, just the output format.
</p>

<p>
goldentests are more generic too.
for instance you could use it for compiler or linter warnings.
one of the generated output files could be warnings.
the diff tool for this would be smart enough to remove preexisting ones.
so whenever you are working on some code,
you would only see the new warnings that you introduce.
sure, sometimes a warning is wrong (otherwise it would be an error),
this method lets you acknowledge the warning and still commit,
without adding silly &quot;nolint&quot; comments to silence the warning forever.
the warning will be silenced automatically from the point of the commit.
if the reviewer thinks this is undesired,
they can ask the change&apos;s author
to add a todo to address the warning in the future.
this shines the best when you want to enable a new warning for your codebase.
you can simply enable the warning and ignore the resulting diff.
nobody will see that new warning for existing code,
so you are not adding a large burden on others suddenly.
the warning will only appear for new code which people will then address.
and the warning is still in the full generated file,
so if you want to clean up the whole codebase yourself,
you can just simply fix the existing instances one by one
and see that the number of warnings go down over time.
</p>

<p>
there&apos;s a practice of writing tests first, code later.
goldentests work for this too!
you can simply write down the expected output of your test app,
and then keep hacking at your library and test app code
until you get diff neutral.
you can write down the expected output without code or compiler.
maybe your teammate can just write down sample inputs and sample outputs,
and you can readily use that, no need to put it into assertions.
</p>

<p>
if you ever done coding competitions (acm icpc, topcoder, hackerrank)
then that environment is totally like this
and it&apos;s quite a satisfying environment,
especially when you see that your code passes all the tests.
when you solve a problem there,
you are usually pretty confident about your code.
and all they needed is some sample input and output text files.
furthermore all such testing is independent of the programming language.
with diff testing you can decide that you&apos;ll rewrite your slow python script
into some fast c++ code.
with unittesting it can be quite hard to see
that your rewrite had no effect on the logic.
with goldentesting all you need to verify is that the diffs are neutral
and then you&apos;ll be pretty much confident about your change.
</p>

<p>
at work i decided to write a little script
that parses a schedule file and outputs a nice text calendar
to visualise who is on duty and when.
actually, such calendar visualizations already existed,
what i really wanted is to visualize the diffs in a calendar
whenever someone is making a change to the schedule.
such a tool didn&apos;t exist before for these schedule files.
so i wrote a tool that parses and compares the old and new schedule files,
and then displays a calendar that has the differing days highlighted.
this is an example of one writing a special diffing tool:
most of the time the total state doesn&apos;t really matter,
all we care about is the diff.
but that&apos;s not even the point:
my point is that i didn&apos;t write any ordinary unittests for this tool.
all i did is that i hand written some sample inputs (old+new file pairs),
and just committed the generated output from them
since there&apos;s no good standard tooling for tracking golden diffs so far.
i kept adding inputs until i reached very high code coverage
as reported by the coverage tools.
when i reached that, i was confident that i handled most edge cases.
and obviously i carefully verified
that the output is what it should be for all the sample inputs.
</p>

<p>
it worked out great.
the most utility came after i released the tool
and people pointed out that i made a few wrong assumptions about the schedules.
so whenever i fixed a bug,
all i needed to do is to add a new sample input to cover that case.
or if it altered the output of an existing case,
it was very easy and obvious to see what was the effect of my change.
i usually don&apos;t get such a visceral feedback from unittests.
or sometimes people wanted me to alter the output a bit.
that was easy to do: i made formatting change
and in the diffs it was easy to see how the new format looked like.
i still love maintaining this piece of code
because it&apos;s super easy to make changes in it
while maintaining a high confidence in its correctness.
</p>

<p>
another example of such an environment would be
the deployment configs of the service of the team i worked at once.
this was a huge service consisting of many binaries running in many locations.
the system that runs these binaries needs the configuration
in a very denormalized manner.
so in the end we need to have (binaries * locations) number of configs.
to generate those configs we obviously use lot of templating.
there is a shared template
but then each binary must customize that (e.g. different cmdline arguments)
and then each location can have further customizations
(e.g. to test something in a single location only).
how would you test something like that?
you can&apos;t really.
e.g. you set a new cmdline flag for a binary to launch your new feature.
do you add a test into the configs that a flag is set?
that would be pretty dumb busywork.
what we had instead is that
for each change we just generated all the old+new denormalized configs
and then you inspected the diffs and verified
that your change does what you expected.
however on its own there would be massive diffs
just because of the sheer amount of binaries and locations we had.
e.g. you make a cmdline flag change in a binary&apos;s config
and now you have 30 files with a diff because we have 30 locations.
so we had a tool that canonicalized the diffs
(replaced references to location names with a placeholder string),
then it hashed the diffs
(just the lines with a diff, unchanged lines didn&apos;t matter),
and grouped the files into buckets based on their diff hash.
this worked out pretty nice since each cmdline flag was on their own line.
so what you actually need to do is to review a single diff
because then you can be sure that the rest of the diffs are the same.
if a single location has some special logic on the flag you are changing
and the diff looks different then that diff will go into a different bucket,
so you&apos;ll notice that too.
(sidenote: it&apos;s true that in this system weird overrides can silence some diffs,
but this could be combated with good discipline called &quot;weird needs to expire&quot;.
so all such weird overrides must have a clear deadline associated with them
at which point somebody will follow up and hopefully remove it.)
</p>

<p>
anyways, the point here is that i quite liked working in this system
simply because my confidence was very high in it.
the configuration pipeline was quite a mess
and sometimes very hard to understand,
but at least silly unittests weren&apos;t getting into my way
whenever i wanted to make a change.
i just made a change, looked at the diff,
and if if looked right, i knew it was fine.
this also made the review much much easier.
sometimes people implement quite complicated logic to achieve a thing.
but i don&apos;t really need to obsess too much about the logic itself.
all i need to look at the result and if it looks right,
i&apos;m not anxious about approving something that might be wrong.
even if it&apos;s wrong, i can see that it works for the cases we care about,
so it doesn&apos;t need to keep me up at night.
</p>

<p>
there&apos;s one caveat to this.
if you generate such a golden output,
make sure the output is deterministic and easy to diff.
if you want to output a list then sort it and output the entries line by line.
randomly ordered output would give you lots of spurious diffs
that no human can easily understand.
with too much info on a single line it&apos;s hard to see
where the diff begins and where it ends.
often you want to make a change but then see that the diff is hard to review.
to alleviate this issue, if it appears, you can just prepare another change
that changes the output such that
it will make your subsequent change easy to review.
e.g. you make change that sorts a previously unsorted list.
two small focused diffs are often much easier to review
than one larger one that does too many things at once.
</p>

<p>
however there is one significant area
where golden diffs are really lacking in tooling: interaction tests.
maybe you have some client server architecture
and you want to verify that the interactions between them look good.
here&apos;s how i imagine testing such a thing.
let&apos;s assume we want to test a client&apos;s interaction with a server.
ideally there would be a tool that can record the request/reply interations.
so first i&apos;d run my client against the real server
and i&apos;d record the interactions.
then there would be a tool that could act as a fake server
with some preconfigured request/reply behavior.
then during the test i&apos;d just assert
that the interactions against the fake server
are exactly the same as in the golden recorded interactions.
these interactions would be committed along the code,
since during the test it would infeasible to bring up that server.
if the test interactions don&apos;t match,
i&apos;d rerun the recording tool
to rerecord the interactions against the real server and commit that.
so in the review one could see how the interactions changed too.
this is quite similar to what happens in interaction unittests already
but there people manually copy paste the interactions into assertions.
in this solution that would be replaced by running a single tool.
</p>

<p>
now as with all things in life
the question between explicit asserts and implicit diffs as tests
is a question of tradeoffs.
assertions have their place too in some cases.
e.g. when you know there is no point in continuing some logic
then sure, assert it away.
and then maybe you can enforce that all tests must run successfully to end.
so basically you have a bit of both.
but i really hope that over time the tooling will improve just enough
that this idea will catch on and then hopefully life will be much easier
for code maintainers in general.
</p>

<p>
now it&apos;s true that acknowledging a diff is much easier
than painstakingly update an assertion or expectation.
so chances are that this might lead to more mistakes.
however i&apos;m not convinced that we should avoid mistakes at all costs.
rather, we should strive for an environment where mistakes are cheap.
changes should be rolled out progressively,
changes should be able to easily rolled back, and so on.
then we can focus more on the useful, new developments,
rather than doing busywork with maintaining silly assertions.
</p>

<p>
i&apos;ve tried talking with a few folks about this.
so far i managed to convince nobody about this idea.
fortunately this theory of mine would be quite easy to &quot;test&quot;.
i mean a sociological experiment on developers.
you devise a project that a person has to finish.
you make a version with goldentests and a version with unittests.
then you divide people into two groups:
one gets the goldentest one and is instructed to continue with that,
the other one gets the unittest one and is instructed to continue with that.
after the experiment you run a survey
on how easy it was to work with the project
and how confident are their about their code&apos;s correctness.
you also review the time it took to finish the project,
and also review their code to see how many mistakes they missed.
i predict that the goldentest group will take less time,
will be more confident about their code,
and the correctness rate will be just about equal.
the only problem is i&apos;m too lazy and inexperienced to run such an experiment.
i hope one day someone runs it and then we&apos;ll see if i was right or not.
</p>

<h2 id="postmore">postmore</h2>
<p>
when i partake in some philosophical email discussions,
i tend to write overly long emails.
and usually such emails contain thoughts about multiple topics.
this can be quite exhausting for the recipient to read and respond.
</p>

<p>
often those subtopics could be a blog post on their own.
while i appreciate the nuance and understanding that comes from 1:1 discussions,
there&apos;s no reason to limit ideas to two people.
ideas are meant to be exchanged!
maybe twitter was right: one should keep the direct messages short.
instead we should write more on our public spaces
and simply link them in discussions.
when a reader wants to respond, they can just write their own public post.
not responding to a public post feels less rude
than not responding to a direct message.
it feels much easier to ignore a link than a long passage of text in an email.
</p>

<p>
this is not the same as a forum discussion.
first, forum posts are in a context of a thread,
while a blog post ideally stands on its own.
you can&apos;t just write &quot;this is dumb&quot; as a post on its own.
second, you can disable comments on your own blog,
and then you&apos;ll get less responses so you&apos;ll have to worry less about them.
besides, more often than not,
comments bikeshed about the small points, or the specific metaphores you used,
rather than talking about the overall message of the post.
this then makes the comments section not a very informative place.
if one has an insightful addendum or rebuttal,
they should write a post on their own, notify the original author,
and that author should link to that post in their original post.
this is a lot more effort than comments,
but i think the resulting quality is worth the effort over the long term.
it also limits the amount of the content associated with each post
which is rather quite an underappreciated quality these days.
</p>

<p>
in other words i&apos;m suggesting that people should blog more.
sure, more posts mean less quality and more half digested ideas.
but i think that&apos;s fine, the posts don&apos;t have to be perfect.
maybe over time you learn more and completely disagree with your old posts,
or maybe even regret or are ashamed of your old posts.
i think it&apos;s still worth to keep the old posts,
so that people can see how you changed over time.
you can simply edit that old post to include links to your updated views.
eventually we&apos;ll all die and everything will be in vain,
so in the end there&apos;s nothing to lose by opening up a little bit
and writing about the thoughts swirling in one&apos;s head.
</p>

<p>
i&apos;m actually trying to convince myself to write more with this post.
i have a lot of small things
that i just want to see written down somewhere publicly.
most of them are possibly dumb things that i&apos;m somewhat reluctant to share.
but maybe i shouldn&apos;t be and i should still make a post about them
even if it&apos;s like a one sentence&apos;s worth of content.
even this post fits that criteria:
i don&apos;t really have anything interesting to say here,
and yet i&apos;m already in the 5th paragraph.
actually, this post is very similar to the freewriting i often do in notebooks.
just jotting down thoughts one after the other as they come.
now that i&apos;m doing it for a long time, i see the psychological benefits
of having a much calmer, less stressed mind in general.
so i might as well do it in the form of posts more often.
and others should write more too!
</p>

<h2 id="slowpals">slowpals</h2>
<p>
i really like discussing various ideas.
i especially like when people challenge my views
since that means i can sharpen my arguments or perhaps change my views.
</p>

<p>
however doing this in an online discussion forum is quite exhausting.
if you post something dumb in a public space,
then you get lot of responses, some of them mean even.
it&apos;s infeasible and pointless to respond to everyone.
even if you do,
you might still get another barrage of responses to any of your replies.
</p>

<p>
one solution to this is to avoid public discussions.
private discussions are often more fruitful
because you have more time and energy to focus
on really understanding that single person&apos;s perspective.
you&apos;ll be more likely be able to stand in their shoes
if this other person is open to invest the energy to make this happen.
</p>

<p>
for online discussions i believe plain text emails is a good way to discuss.
this means what you need is a good penpal finding site rather than a forum.
since one doesn&apos;t really want to reveal their email address nilly-willy,
ideally the platform would allow exchanging messages through itself.
however even with penpal sites,
it&apos;s very likely that you send a letter to someone,
and then you don&apos;t get any feedback or response to your letter,
and then you don&apos;t know if you were rude,
or if your partner just lacks the energy to respond.
ideally there would be something that incentivizes users to respond.
</p>

<p>
so here&apos;s an idea for a penpal site
that i think could be quite trivial to implement,
and requires almost no resources even.
this would an online platform that could easily scale up to millions of users
and still be operated from a small raspberry pi
because you could outsource many of its operations to free online services.
i&apos;d totally implement it myself if i knew of a couple folks that would sign up.
</p>

<p>
it would consist of two parts:
a static online site that lists all the profiles along with the profile data;
and an email address through which one can interact with the platform.
</p>

<p>
the static online site would be a plaintext document (hosted on e.g. github)
that just lists the usernames and their profile text.
i wouldn&apos;t bother with profile pics and whatnot, plaintext should be enough.
</p>

<p>
then i&apos;d have an email address, e.g. slowpals at gmail,
and the users have to register and talk to others through that address.
e.g. an user wishing to register could send an email to slowpals+admin at gmail
with a title &quot;register &lt;usename&gt;&quot; and with their profile text as the body.
then a script would process this email
and upload their profile to that online site above.
(in emails everything after + is ignored, so you can use that for such tricks.)
</p>

<p>
now comes the interesting part: exchanging messages.
suppose alice notices and likes bob&apos;s profile.
she can start a conversation by sending an email to slowpals+bob at gmail.
slowpals will then forward the email to bob&apos;s private address.
however there are three important rules that would make this interesting.
</p>

<ul><li>
  oneaday rule: you can send and receive a single message per day.
</li><li>
  replyfirst rule: you can&apos;t send or receive another message
  until you responded to your most recently received message.
</li><li>
  onethread rule: you can only have one active thread by person.
</li>
</ul>

<p>
my goal here is to artificially &quot;slow down&quot; conversations
in the hopes that they remain more civilized this way.
rather than delivering all the messages at send time,
slowpals would queue them up, and deliver them one at a time.
each user would have a first in first out queue.
so if charlie also sends a message to bob,
bob will receive the message from charlie only the next day
after he responded to alice.
and bob can expect a response from alice:
the only way to not receive one is
if alice decides to not use the site anymore.
alice will not have access to the rest of the members
until she responded to bob&apos;s email.
this also ensures that one doesn&apos;t get a barrage of emails.
one can expect that on this site one only receives a few messages,
and that one will never be overwhelmed by them.
in fact, this platform degrades gracefully:
if you stop responding, slowpals will stop nagging you,
it&apos;s as if you simply deactivated your account
and i&apos;d even delete your profile from the public listing
if you didn&apos;t respond to an email for a month.
</p>

<p>
there&apos;s one point to note:
there should be a way to end conversations
so that they don&apos;t go forever for no good reason.
it should be possible to annotate messages for which you don&apos;t expect a reply.
the same way it should be possible to report spam messages.
i&apos;m thinking of using the first line of message for optional directives.
e.g. for a message like this (involving slowpals+alice and slowpals+bob):
</p>

<pre>
  !noreply
</pre>

<pre>
  hi alice! it was nice chatting with you! cheers!
</pre>

<p>
alice wouldn&apos;t be expected to respond.
she would get this email and the next day she would get another one
regardless if she responded or not.
that day she can start a new conversation with another member instead.
</p>

<p>
note that the oneaday rule makes it hard to start new conversations
when your queue is not empty.
i think this can be considered a feature rather than a bug.
you should make the most of your existing conversations
and you should respond promptly.
most people are quite lazy when it comes to emails,
so eventually your queue would drop to zero,
which would also allow you to start new threads.
</p>

<p>
the slowness might be annoying when you start to like the other person.
however in that situation you can exchange your real email address
and you can have your discussions in real time.
</p>

<p>
and it would be quite easy to implement this site
since the email queues would be stored in gmail.
all i need is a daily cronjob that processes these emails
and forwards the messages according to the above rules.
and after i forwarded a message, i can simply delete it from gmail.
it&apos;s quite nice from the user data perspective,
since i only need to store queued emails.
the only sensitive data that needs to be carefully maintained
is the password to this gmail address and the username to email address mapping.
</p>

<p>
to keep this simple, i&apos;d probably also enforce a plaintext rule:
if you send an email with html or with attachments,
i&apos;d just simply reject your email.
i&apos;d limit the message size to 100k too.
and i&apos;d highly encourage people to strip the previous message from the body
since i really don&apos;t see the value of that in this context.
</p>

<p>
with such rules i&apos;d totally try participating in such a community.
i don&apos;t think anybody reads this blog but if you do
and you like the idea of such a penpal site then let me know.
then i might be motivated enough to build it.
or if you know that such a site already exists,
then also let me know, i might sign up.
</p>
<hr><p>the rest of the entries can be found at
<a href=https://html.notech.ie>html.notech.ie</a>.</p>
</div></body></html>
